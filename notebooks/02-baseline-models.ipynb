{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# 02 - ModÃ¨les Baseline pour la Classification de Radiographies COVID-19\n",
                "\n",
                "**Objectif**: ImplÃ©menter et Ã©valuer des modÃ¨les baseline (Logistic Regression, Random Forest, SVM) pour la classification de radiographies thoraciques.\n",
                "\n",
                "**Features utilisÃ©es**: \n",
                "- `mean_intensity` : IntensitÃ© moyenne des pixels\n",
                "- `std_intensity` : Ã‰cart-type de l'intensitÃ©\n",
                "- `contrast` : Ratio std/mean\n",
                "- `entropy` : Entropie de Shannon (complexitÃ© de texture)\n",
                "- `gradient` : Gradient Sobel moyen (intensitÃ© des contours)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import os\n",
                "import sys\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "\n",
                "# Add src to path for local imports\n",
                "sys.path.insert(0, os.path.abspath('..'))\n",
                "\n",
                "from src.features.build_features import build_feature_dataset, load_or_build_features\n",
                "from src.models.train_model import train_all_models, get_feature_importance, FEATURE_COLS\n",
                "from src.models.predict_model import plot_confusion_matrix, plot_feature_importance, generate_report\n",
                "\n",
                "# Settings\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('viridis')\n",
                "%matplotlib inline\n",
                "\n",
                "print(\"Imports OK\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "data-section",
            "metadata": {},
            "source": [
                "## 1. Chargement des Features\n",
                "\n",
                "Chargement ou extraction des 5 features statistiques (voir `01-projet.ipynb` pour l'analyse exploratoire)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration des chemins\n",
                "# âš ï¸ MODIFIER CE CHEMIN SI NÃ‰CESSAIRE\n",
                "DATA_DIR = \"../data/COVID-19_Radiography_Dataset\"\n",
                "FEATURES_CACHE = \"../data/features.csv\"\n",
                "MODELS_DIR = \"../models\"\n",
                "REPORTS_DIR = \"../reports\"\n",
                "\n",
                "os.makedirs(os.path.join(REPORTS_DIR, 'figures'), exist_ok=True)\n",
                "\n",
                "# Extraction des features (ou chargement depuis le cache)\n",
                "df_features = load_or_build_features(DATA_DIR, cache_path=FEATURES_CACHE)\n",
                "\n",
                "print(f\"\\nDataset shape: {df_features.shape}\")\n",
                "df_features.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "training-section",
            "metadata": {},
            "source": [
                "## 2. EntraÃ®nement des ModÃ¨les Baseline\n",
                "\n",
                "Nous allons entraÃ®ner 3 modÃ¨les baseline:\n",
                "1. **Logistic Regression** - Baseline linÃ©aire simple\n",
                "2. **Random Forest** - MÃ©thode ensemble robuste\n",
                "3. **SVM (RBF Kernel)** - Classifieur non-linÃ©aire"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train-models",
            "metadata": {},
            "outputs": [],
            "source": [
                "# EntraÃ®nement de tous les modÃ¨les baseline\n",
                "# Cross-validation 5-fold + Ã©valuation sur test set (20%)\n",
                "\n",
                "results = train_all_models(\n",
                "    df=df_features,\n",
                "    save_dir=MODELS_DIR\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "evaluation-section",
            "metadata": {},
            "source": [
                "## 3. Ã‰valuation et Analyse des RÃ©sultats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "comparison-table",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tableau comparatif des performances\n",
                "comparison_data = []\n",
                "for name, res in results.items():\n",
                "    comparison_data.append({\n",
                "        'ModÃ¨le': name,\n",
                "        'CV Accuracy': f\"{res['train']['cv_mean']:.4f} Â± {res['train']['cv_std']:.4f}\",\n",
                "        'Test Accuracy': f\"{res['eval']['accuracy']:.4f}\",\n",
                "        'F1 Weighted': f\"{res['eval']['f1_weighted']:.4f}\",\n",
                "        'Precision': f\"{res['eval']['precision_weighted']:.4f}\",\n",
                "        'Recall': f\"{res['eval']['recall_weighted']:.4f}\"\n",
                "    })\n",
                "\n",
                "comparison_df = pd.DataFrame(comparison_data)\n",
                "comparison_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "confusion-matrices",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matrices de confusion pour chaque modÃ¨le\n",
                "le = joblib.load(os.path.join(MODELS_DIR, 'label_encoder.joblib'))\n",
                "class_names = le.classes_\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "for idx, (name, res) in enumerate(results.items()):\n",
                "    cm = res['eval']['confusion_matrix']\n",
                "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
                "    \n",
                "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
                "                xticklabels=class_names, yticklabels=class_names, ax=axes[idx])\n",
                "    axes[idx].set_title(f'{name}\\nAccuracy: {res[\"eval\"][\"accuracy\"]:.4f}', fontsize=12, fontweight='bold')\n",
                "    axes[idx].set_ylabel('True Label')\n",
                "    axes[idx].set_xlabel('Predicted Label')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(REPORTS_DIR, 'figures', 'confusion_matrices_comparison.png'), dpi=300, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feature-importance",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance (Random Forest)\n",
                "importance_df = get_feature_importance(os.path.join(MODELS_DIR, 'random_forest.joblib'))\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "bars = ax.barh(importance_df['feature'], importance_df['importance'], color='steelblue')\n",
                "ax.set_xlabel('Importance', fontsize=12)\n",
                "ax.set_title('Random Forest - Importance des Features', fontsize=14, fontweight='bold')\n",
                "\n",
                "for bar, val in zip(bars, importance_df['importance']):\n",
                "    ax.text(val + 0.005, bar.get_y() + bar.get_height()/2, f'{val:.3f}', va='center')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(os.path.join(REPORTS_DIR, 'figures', 'feature_importance.png'), dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"Top features:\")\n",
                "importance_df.sort_values('importance', ascending=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "per-class-metrics",
            "metadata": {},
            "outputs": [],
            "source": [
                "# MÃ©triques par classe - Meilleur modÃ¨le\n",
                "best_model_name = max(results.keys(), key=lambda x: results[x]['eval']['f1_weighted'])\n",
                "best_result = results[best_model_name]\n",
                "\n",
                "print(f\"Meilleur modÃ¨le: {best_model_name}\")\n",
                "print(f\"F1 Weighted: {best_result['eval']['f1_weighted']:.4f}\\n\")\n",
                "\n",
                "class_report = best_result['eval']['classification_report']\n",
                "metrics_data = []\n",
                "for class_name in class_names:\n",
                "    if class_name in class_report:\n",
                "        cr = class_report[class_name]\n",
                "        metrics_data.append({\n",
                "            'Classe': class_name,\n",
                "            'Precision': f\"{cr['precision']:.4f}\",\n",
                "            'Recall': f\"{cr['recall']:.4f}\",\n",
                "            'F1-Score': f\"{cr['f1-score']:.4f}\",\n",
                "            'Support': int(cr['support'])\n",
                "        })\n",
                "\n",
                "pd.DataFrame(metrics_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "analysis-section",
            "metadata": {},
            "source": [
                "## 4. Conclusions et InterprÃ©tations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "conclusions",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sauvegarde des rÃ©sultats\n",
                "comparison_df.to_csv(os.path.join(REPORTS_DIR, 'baseline_comparison.csv'), index=False)\n",
                "\n",
                "best_acc = max(results.values(), key=lambda x: x['eval']['accuracy'])['eval']['accuracy']\n",
                "best_f1 = max(results.values(), key=lambda x: x['eval']['f1_weighted'])['eval']['f1_weighted']\n",
                "lr_acc = results['Logistic Regression']['eval']['accuracy']\n",
                "rf_acc = results['Random Forest']['eval']['accuracy']\n",
                "svm_acc = results['SVM']['eval']['accuracy']\n",
                "\n",
                "print(f\"\"\"\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "                        CONCLUSIONS ET INTERPRÃ‰TATIONS\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "ğŸ“Š RÃ‰SULTATS OBTENUS:\n",
                "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
                "   â”‚ ModÃ¨le                 â”‚ Accuracy   â”‚ F1 Weightedâ”‚\n",
                "   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
                "   â”‚ Random Forest          â”‚ {rf_acc:.1%}     â”‚ {results['Random Forest']['eval']['f1_weighted']:.4f}     â”‚\n",
                "   â”‚ SVM (RBF)              â”‚ {svm_acc:.1%}     â”‚ {results['SVM']['eval']['f1_weighted']:.4f}     â”‚\n",
                "   â”‚ Logistic Regression    â”‚ {lr_acc:.1%}     â”‚ {results['Logistic Regression']['eval']['f1_weighted']:.4f}     â”‚\n",
                "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                "\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "ğŸ” INTERPRÃ‰TATIONS:\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "1ï¸âƒ£  PERFORMANCE GLOBALE:\n",
                "    â€¢ Random Forest domine avec {rf_acc:.1%} d'accuracy\n",
                "    â€¢ C'est {rf_acc/0.25:.1f}x mieux que le hasard (25% pour 4 classes)\n",
                "    â†’ Les features extraites contiennent de l'information discriminante\n",
                "\n",
                "2ï¸âƒ£  LOGISTIC REGRESSION SOUS-PERFORME (~50%):\n",
                "    â€¢ Performance proche du hasard pour un problÃ¨me Ã  4 classes\n",
                "    â†’ Les classes ne sont PAS linÃ©airement sÃ©parables dans l'espace des 5 features\n",
                "    â†’ Confirme la nÃ©cessitÃ© de modÃ¨les non-linÃ©aires (RF, SVM RBF)\n",
                "\n",
                "3ï¸âƒ£  Ã‰CART CV vs TEST FAIBLE (~0.5%):\n",
                "    â€¢ Pas d'overfitting majeur dÃ©tectÃ©\n",
                "    â†’ Les modÃ¨les gÃ©nÃ©ralisent correctement sur des donnÃ©es non vues\n",
                "\n",
                "4ï¸âƒ£  F1 > ACCURACY POUR LOGISTIC REGRESSION:\n",
                "    â€¢ Le F1 weighted (0.51) > Accuracy (0.49)\n",
                "    â†’ Le class_weight='balanced' aide Ã  mieux gÃ©rer les classes minoritaires\n",
                "\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "âš ï¸  LIMITES DE L'APPROCHE:\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "   â€¢ {rf_acc:.0%} reste INSUFFISANT pour un diagnostic mÃ©dical fiable\n",
                "   \n",
                "   Les 5 features statistiques globales (mean, std, entropy...) ne capturent pas:\n",
                "   âŒ La LOCALISATION des opacitÃ©s pulmonaires\n",
                "   âŒ Les PATTERNS SPATIAUX caractÃ©ristiques du COVID (ground-glass opacity)\n",
                "   âŒ Les STRUCTURES ANATOMIQUES (poumons, mÃ©diastin, cÃ´tes)\n",
                "\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "ğŸ“‹ RECOMMANDATIONS POUR AMÃ‰LIORER:\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "   1. FEATURES SPATIALES:\n",
                "      â€¢ HOG (Histogram of Oriented Gradients) - capture les contours locaux\n",
                "      â€¢ LBP (Local Binary Patterns) - capture les textures locales\n",
                "   \n",
                "   2. DEEP LEARNING:\n",
                "      â€¢ CNN prÃ©-entraÃ®nÃ© (ResNet, VGG, EfficientNet)\n",
                "      â€¢ Transfer learning depuis ImageNet\n",
                "   \n",
                "   3. SEGMENTATION:\n",
                "      â€¢ Utiliser les masques pulmonaires disponibles dans data/*/masks/\n",
                "      â€¢ Focaliser l'analyse sur les rÃ©gions pulmonaires uniquement\n",
                "\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "âœ… Rapports sauvegardÃ©s dans: {REPORTS_DIR}\n",
                "âœ… ModÃ¨les sauvegardÃ©s dans: {MODELS_DIR}\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\"\"\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}